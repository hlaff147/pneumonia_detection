{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import add\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "np.random.seed(777)\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "ALPHA = 2e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) \n",
    "                resized_arr = cv2.resize(img_arr, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betin\\AppData\\Local\\Temp\\ipykernel_22140\\2126597077.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data)\n"
     ]
    }
   ],
   "source": [
    "train = get_data('./archive/chest_xray/chest_xray/train')\n",
    "test = get_data('./archive/chest_xray/chest_xray/test')\n",
    "val = get_data('./archive/chest_xray/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.append(train, val, axis=0)\n",
    "train, val = train_test_split(train, test_size=.20, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for feature, label in data:\n",
    "        x.append(feature)\n",
    "        y.append(label)\n",
    "        \n",
    "    x = (np.array(x) / 255).reshape(-1,IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "    y = np.array(y)\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = prepare_data(train)\n",
    "x_val, y_val = prepare_data(val)\n",
    "x_test, y_test = prepare_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20, \n",
    "    zoom_range = 0.2, \n",
    "    width_shift_range=0.15,  \n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip = False,  \n",
    "    vertical_flip=False)\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weights = {0: weights[0], 1: weights[1]}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(inputs, filters, stride):\n",
    "    conv_0 = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(stride, stride), padding='same', activation='relu')(inputs)\n",
    "    conv_1 = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(stride, stride), padding='same', activation='relu')(conv_0)\n",
    "    \n",
    "    skip = layers.Conv2D(input_shape=input_size, filters=filters, kernel_size=(1, 1), strides=(stride**2, stride**2), padding='same', activation='relu')(inputs)\n",
    "    \n",
    "    pool = layers.MaxPool2D(pool_size=(3, 3), strides=(2,2), padding='same')(add([conv_1, skip]))\n",
    "    \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_size, name='input')\n",
    "\n",
    "y_0 = block(inputs, 16, 2)\n",
    "y_1 = block(y_0, 32, 1)\n",
    "y_2 = block(y_1, 48, 1)\n",
    "y_3 = block(y_2, 64, 1)\n",
    "y_4 = block(y_3, 80, 1)\n",
    "\n",
    "gap = layers.GlobalMaxPooling2D()(y_4)\n",
    "dense = layers.Dense(2, activation='relu')(gap)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"pneumonia_wnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.7, min_delta=ALPHA, patience=7, verbose=1)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS = [lr_reduce, early_stopping_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy',\n",
    "          tf.keras.metrics.Precision(name='precision'),\n",
    "          tf.keras.metrics.Recall(name='recall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=ALPHA),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train,y_train, batch_size = BATCH_SIZE),\n",
    "                    steps_per_epoch=x_train.shape[0]/BATCH_SIZE, \n",
    "                    validation_data = (x_val, y_val),\n",
    "                    validation_steps=x_val.shape[0]/BATCH_SIZE,\n",
    "                    callbacks = CALLBACKS,\n",
    "                    class_weight = weights,\n",
    "                    epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "predictions[predictions >= 0.5] = 1\n",
    "predictions[predictions < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
